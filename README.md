# NEURA AI ğŸ¤– â€” InteligÃªncia Artificial Multimodal Local

[![VersÃ£o](https://img.shields.io/badge/vers%C3%A3o-0.3.0-blue.svg)](https://github.com/DrkCde15/NEURA)
[![Python](https://img.shields.io/badge/python-3.8+-yellow.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**NEURA AI** Ã© um ecossistema de inteligÃªncia artificial modular desenvolvido em Python, focado em **Multimodalidade Local**. Projetado para ser leve e resiliente, ele permite interaÃ§Ãµes avanÃ§adas de texto e visÃ£o computacional, rodando inteiramente no seu hardware ou via tÃºnel privado.

O diferencial da Neura Ã© sua arquitetura desacoplada que utiliza **LLMs locais via Ollama**, uma **MemÃ³ria Persistente Contextual (SQLite)** e um sistema de **Acesso Remoto Seguro** automatizado via LocalTunnel, garantindo que sua IA pessoal esteja disponÃ­vel em qualquer lugar sem comprometer a privacidade.

---

## ğŸ“‚ Estrutura do Projeto

```text
NEURA/
â”œâ”€â”€ neura_ai/               # Core da biblioteca
â”‚   â”œâ”€â”€ config.py           # Central de configuraÃ§Ãµes (Modelos, URLs, DB)
â”‚   â”œâ”€â”€ core.py             # CÃ©rebro: GestÃ£o de MemÃ³ria SQL e Chat
â”‚   â”œâ”€â”€ image.py            # Especialista em VisÃ£o Computacional (PIL/Base64)
â”‚   â””â”€â”€ __init__.py         # InicializaÃ§Ã£o do pacote (v0.3.0)
â”œâ”€â”€ ecosystem.config.js     # AutomaÃ§Ã£o PM2 (Servidor Ollama + TÃºnel Local)
â”œâ”€â”€ pyproject.toml          # ConfiguraÃ§Ã£o de empacotamento PyPI/Pip
â”œâ”€â”€ .gitignore              # ProteÃ§Ã£o de dados sensÃ­veis e logs
â”œâ”€â”€ requirements.txt        # DependÃªncias (ollama, Pillow, requests)
â””â”€â”€ README.md               # VocÃª estÃ¡ aqui!
```

---

## âœ¨ Principais Funcionalidades

- **ğŸ§  MemÃ³ria Persistente:** HistÃ³rico de conversas automÃ¡tico via SQLite, permitindo que a IA se lembre de interaÃ§Ãµes passadas.
- **ğŸ‘ï¸ VisÃ£o Computacional:** Processamento otimizado de imagens (redimensionamento para 320px) com o modelo `moondream`.
- **ğŸŒ Acesso Remoto Inteligente:** IntegraÃ§Ã£o nativa com **LocalTunnel** com bypass automÃ¡tico de seguranÃ§a (headers).
- **ğŸ’“ Health Check Integrado:** MÃ©todo para verificar se o servidor de IA estÃ¡ online antes de enviar requisiÃ§Ãµes.
- **âš™ï¸ ConfiguraÃ§Ã£o Centralizada:** `config.py` permite trocar modelos (`qwen2`, `llama3`, etc) e parÃ¢metros sem alterar o cÃ³digo principal.
- **ğŸ›¡ï¸ ResiliÃªncia Industrial:** Tratamento de erros para falhas de rede, rede indisponÃ­vel e problemas de codificaÃ§Ã£o.
- **âš¡ AutomaÃ§Ã£o com PM2:** Gerenciamento de processos para manter o servidor e o tÃºnel ativos 24/7.

---

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. PrÃ©-requisitos

- [Ollama](https://ollama.com/) instalado.
- [Node.js](https://nodejs.org/) (para LocalTunnel e PM2).
- Python 3.8 ou superior.

### 2. InstalaÃ§Ã£o Tradicional

```bash
# Clone o repositÃ³rio ou baixe os arquivos
pip install -e .
```

### 3. ConfiguraÃ§Ã£o do Servidor (Windows)

Para permitir acesso remoto via rede local ou tÃºnel, configure as variÃ¡veis de ambiente:

```powershell
$env:OLLAMA_HOST="0.0.0.0"
$env:OLLAMA_ORIGINS="*"
```

### 4. AutomaÃ§Ã£o (PM2)

Mantenha sua IA sempre online com gerenciamento de processos:

```bash
npm install -g pm2 localtunnel
pm2 start ecosystem.config.js
pm2 save
```

---

## ğŸ› ï¸ Exemplos de Uso

### Uso Local (com HistÃ³rico SQLite)

A Neura gerencia o contexto automaticamente para vocÃª.

```python
from neura_ai.core import Neura

# Inicializa com prompt de sistema personalizado
n = Neura(system_prompt="VocÃª Ã© um assistente tÃ©cnico especializado em Python.")

# Verifica se o servidor estÃ¡ online
if n.health_check():
    print(n.get_response("Como posso otimizar um loop em Python?"))
else:
    print("O servidor Ollama nÃ£o estÃ¡ acessÃ­vel.")
```

### InteligÃªncia Visual

A Neura processa a imagem localmente antes de enviar, economizando largura de banda:

```python
from neura_ai.core import Neura

n = Neura()
feedback = n.get_response("O que vocÃª vÃª nesta imagem?", image_path="foto.jpg")
print(f"AnÃ¡lise da IA: {feedback}")
```

### Modo Cloud Privada (Remote Access)

Se vocÃª configurou o tÃºnel no `config.py`, pode acessar de qualquer lugar:

```python
from neura_ai.core import Neura
from neura_ai.config import NeuraConfig

# Conecta ao tÃºnel fixo (ex: https://neura-ai.loca.lt)
n = Neura(host=NeuraConfig.TUNNEL_URL)
print(n.get_response("Estou te acessando remotamente?"))
```

---

## âš™ï¸ ConfiguraÃ§Ãµes DisponÃ­veis (`config.py`)

VocÃª pode ajustar os seguintes parÃ¢metros para melhor performance no seu hardware:

- `LLM_MODEL`: Modelo de linguagem (default: `qwen2:0.5b`).
- `VISION_MODEL`: Modelo de visÃ£o (default: `moondream`).
- `IMAGE_SIZE`: Tamanho mÃ¡ximo para redimensionamento (default: `320x320`).
- `DB_PATH`: Caminho do banco de dados SQLite.

---

## ğŸ“œ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT. Veja `LICENSE` para mais informaÃ§Ãµes.

Desenvolvido com ğŸ¤– por [DrkCde15](https://github.com/DrkCde15).
